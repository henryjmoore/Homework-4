{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'name', 'first', 'last', 'compas_screening_date', 'sex', 'dob',\n",
      "       'age', 'age_cat', 'race', 'juv_fel_count', 'decile_score',\n",
      "       'juv_misd_count', 'juv_other_count', 'priors_count',\n",
      "       'days_b_screening_arrest', 'c_jail_in', 'c_jail_out', 'c_case_number',\n",
      "       'c_offense_date', 'c_arrest_date', 'c_days_from_compas',\n",
      "       'c_charge_degree', 'c_charge_desc', 'is_recid', 'r_case_number',\n",
      "       'r_charge_degree', 'r_days_from_arrest', 'r_offense_date',\n",
      "       'r_charge_desc', 'r_jail_in', 'r_jail_out', 'violent_recid',\n",
      "       'is_violent_recid', 'vr_case_number', 'vr_charge_degree',\n",
      "       'vr_offense_date', 'vr_charge_desc', 'type_of_assessment',\n",
      "       'decile_score.1', 'score_text', 'screening_date',\n",
      "       'v_type_of_assessment', 'v_decile_score', 'v_score_text',\n",
      "       'v_screening_date', 'in_custody', 'out_custody', 'priors_count.1',\n",
      "       'start', 'end', 'event', 'two_year_recid'],\n",
      "      dtype='object')\n",
      "Dataframe has 6172 rows and 11 columns.\n",
      "Replace Female with 0.\n",
      "Replace Male with 1.\n",
      "Replace F with 0.\n",
      "Replace M with 1.\n",
      "Trained decision tree with 2057 leaves and training accuracy 0.79.\n",
      "Leaves\tMean accuracy\n",
      "---------------------\n",
      "2\t0.57310\n",
      "4\t0.58084\n",
      "6\t0.58336\n",
      "8\t0.57004\n",
      "10\t0.57112\n",
      "12\t0.57220\n",
      "14\t0.57346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wm/749y2zb56vj71_nxgcgvxdw80000gn/T/ipykernel_41047/2294658904.py:57: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(value, new_value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\t0.57004\n",
      "18\t0.57094\n",
      "20\t0.56878\n",
      "22\t0.57832\n",
      "24\t0.57778\n",
      "26\t0.57796\n",
      "28\t0.58354\n",
      "30\t0.58246\n",
      "32\t0.58228\n",
      "34\t0.58192\n",
      "36\t0.58084\n",
      "38\t0.57976\n",
      "40\t0.58606\n",
      "42\t0.58498\n",
      "44\t0.58624\n",
      "46\t0.58642\n",
      "48\t0.58642\n",
      "50\t0.58606\n",
      "52\t0.58570\n",
      "54\t0.58570\n",
      "56\t0.58570\n",
      "58\t0.58516\n",
      "60\t0.58426\n",
      "62\t0.58426\n",
      "64\t0.58426\n",
      "66\t0.58372\n",
      "68\t0.58246\n",
      "70\t0.58120\n",
      "72\t0.57994\n",
      "74\t0.58012\n",
      "76\t0.57652\n",
      "78\t0.57616\n",
      "80\t0.57940\n",
      "82\t0.57742\n",
      "84\t0.57670\n",
      "86\t0.57616\n",
      "88\t0.57598\n",
      "90\t0.57562\n",
      "92\t0.57706\n",
      "94\t0.57688\n",
      "96\t0.57508\n",
      "98\t0.57490\n",
      "100\t0.57364\n",
      "102\t0.57328\n",
      "104\t0.57364\n",
      "106\t0.57382\n",
      "108\t0.57346\n",
      "110\t0.57328\n",
      "112\t0.57652\n",
      "114\t0.57526\n",
      "116\t0.57454\n",
      "118\t0.57364\n",
      "120\t0.57346\n",
      "122\t0.57364\n",
      "124\t0.57346\n",
      "126\t0.57346\n",
      "128\t0.57256\n",
      "130\t0.57238\n",
      "132\t0.57238\n",
      "134\t0.57256\n",
      "136\t0.57166\n",
      "138\t0.57274\n",
      "140\t0.57256\n",
      "142\t0.57274\n",
      "144\t0.57292\n",
      "146\t0.57202\n",
      "148\t0.57274\n",
      "150\t0.57148\n",
      "152\t0.57094\n",
      "154\t0.57040\n",
      "156\t0.57004\n",
      "158\t0.56986\n",
      "160\t0.56968\n",
      "162\t0.56932\n",
      "164\t0.56860\n",
      "166\t0.56878\n",
      "168\t0.56878\n",
      "170\t0.56716\n",
      "172\t0.56716\n",
      "174\t0.56770\n",
      "176\t0.56698\n",
      "178\t0.56698\n",
      "180\t0.56788\n",
      "182\t0.56752\n",
      "184\t0.56770\n",
      "186\t0.56752\n",
      "188\t0.56698\n",
      "190\t0.56680\n",
      "192\t0.56644\n",
      "194\t0.56770\n",
      "196\t0.56770\n",
      "198\t0.56788\n",
      "200\t0.56716\n",
      "202\t0.56662\n",
      "204\t0.56734\n",
      "206\t0.56698\n",
      "208\t0.56626\n",
      "210\t0.56644\n",
      "212\t0.56554\n",
      "214\t0.56536\n",
      "216\t0.56500\n",
      "218\t0.56482\n",
      "220\t0.56482\n",
      "222\t0.56500\n",
      "224\t0.56572\n",
      "226\t0.56536\n",
      "228\t0.56500\n",
      "230\t0.56482\n",
      "232\t0.56500\n",
      "234\t0.56554\n",
      "236\t0.56428\n",
      "238\t0.56374\n",
      "240\t0.56320\n",
      "242\t0.56247\n",
      "244\t0.56247\n",
      "246\t0.56247\n",
      "248\t0.56572\n",
      "Trained decision tree with 48 leaves has training accuracy 0.59.\n",
      "Trained decision tree with 48 leaves has test accuracy 0.53.\n",
      "Trained decision tree with 39 leaves and test accuracy 0.65.\n",
      "tree without race:\n",
      "|--- priors_count <= 2.50\n",
      "|   |--- age <= 22.50\n",
      "|   |   |--- age <= 20.50\n",
      "|   |   |   |--- priors_count <= 0.50\n",
      "|   |   |   |   |--- age <= 19.50\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- age >  19.50\n",
      "|   |   |   |   |   |--- juv_other_count <= 1.50\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- juv_other_count >  1.50\n",
      "|   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |--- priors_count >  0.50\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |   |--- age >  20.50\n",
      "|   |   |   |--- sex <= 0.50\n",
      "|   |   |   |   |--- class: 0\n",
      "|   |   |   |--- sex >  0.50\n",
      "|   |   |   |   |--- priors_count <= 1.50\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- priors_count >  1.50\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |--- age >  22.50\n",
      "|   |   |--- priors_count <= 0.50\n",
      "|   |   |   |--- age <= 52.50\n",
      "|   |   |   |   |--- sex <= 0.50\n",
      "|   |   |   |   |   |--- c_charge_degree <= 0.50\n",
      "|   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- c_charge_degree >  0.50\n",
      "|   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |--- sex >  0.50\n",
      "|   |   |   |   |   |--- age <= 28.50\n",
      "|   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- age >  28.50\n",
      "|   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |--- age >  52.50\n",
      "|   |   |   |   |--- class: 0\n",
      "|   |   |--- priors_count >  0.50\n",
      "|   |   |   |--- age <= 32.50\n",
      "|   |   |   |   |--- priors_count <= 1.50\n",
      "|   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |--- priors_count >  1.50\n",
      "|   |   |   |   |   |--- sex <= 0.50\n",
      "|   |   |   |   |   |   |--- c_charge_degree <= 0.50\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- c_charge_degree >  0.50\n",
      "|   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- sex >  0.50\n",
      "|   |   |   |   |   |   |--- age <= 24.50\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- age >  24.50\n",
      "|   |   |   |   |   |   |   |--- juv_misd_count <= 0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- juv_misd_count >  0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |--- age >  32.50\n",
      "|   |   |   |   |--- class: 0\n",
      "|--- priors_count >  2.50\n",
      "|   |--- age <= 33.50\n",
      "|   |   |--- priors_count <= 8.50\n",
      "|   |   |   |--- age <= 27.50\n",
      "|   |   |   |   |--- c_charge_degree <= 0.50\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- c_charge_degree >  0.50\n",
      "|   |   |   |   |   |--- age <= 25.50\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- age >  25.50\n",
      "|   |   |   |   |   |   |--- priors_count <= 3.50\n",
      "|   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- priors_count >  3.50\n",
      "|   |   |   |   |   |   |   |--- priors_count <= 4.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- priors_count >  4.50\n",
      "|   |   |   |   |   |   |   |   |--- age <= 26.50\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- age >  26.50\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |--- age >  27.50\n",
      "|   |   |   |   |--- priors_count <= 5.50\n",
      "|   |   |   |   |   |--- sex <= 0.50\n",
      "|   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- sex >  0.50\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- priors_count >  5.50\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |--- priors_count >  8.50\n",
      "|   |   |   |--- class: 1\n",
      "|   |--- age >  33.50\n",
      "|   |   |--- priors_count <= 6.50\n",
      "|   |   |   |--- age <= 55.50\n",
      "|   |   |   |   |--- priors_count <= 4.50\n",
      "|   |   |   |   |   |--- age <= 52.50\n",
      "|   |   |   |   |   |   |--- age <= 43.50\n",
      "|   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- age >  43.50\n",
      "|   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- age >  52.50\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- priors_count >  4.50\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |   |--- age >  55.50\n",
      "|   |   |   |   |--- class: 0\n",
      "|   |   |--- priors_count >  6.50\n",
      "|   |   |   |--- priors_count <= 15.50\n",
      "|   |   |   |   |--- juv_other_count <= 0.50\n",
      "|   |   |   |   |   |--- age <= 59.50\n",
      "|   |   |   |   |   |   |--- juv_misd_count <= 2.50\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- juv_misd_count >  2.50\n",
      "|   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- age >  59.50\n",
      "|   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |--- juv_other_count >  0.50\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |   |--- priors_count >  15.50\n",
      "|   |   |   |   |--- class: 1\n",
      "\n",
      "tree with race:\n",
      "|--- priors_count <= 2.50\n",
      "|   |--- age <= 22.50\n",
      "|   |   |--- age <= 20.50\n",
      "|   |   |   |--- age <= 19.50\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |   |   |--- age >  19.50\n",
      "|   |   |   |   |--- priors_count <= 0.50\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- priors_count >  0.50\n",
      "|   |   |   |   |   |--- sex <= 0.50\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- sex >  0.50\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |--- age >  20.50\n",
      "|   |   |   |--- sex <= 0.50\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |   |   |--- sex >  0.50\n",
      "|   |   |   |   |--- priors_count <= 1.50\n",
      "|   |   |   |   |   |--- race_is_African-American <= 0.50\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- race_is_African-American >  0.50\n",
      "|   |   |   |   |   |   |--- juv_other_count <= 0.50\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- juv_other_count >  0.50\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- priors_count >  1.50\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |--- age >  22.50\n",
      "|   |   |--- priors_count <= 0.50\n",
      "|   |   |   |--- age <= 52.50\n",
      "|   |   |   |   |--- sex <= 0.50\n",
      "|   |   |   |   |   |--- c_charge_degree <= 0.50\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- c_charge_degree >  0.50\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- sex >  0.50\n",
      "|   |   |   |   |   |--- age <= 28.50\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- age >  28.50\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |--- age >  52.50\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |   |--- priors_count >  0.50\n",
      "|   |   |   |--- age <= 32.50\n",
      "|   |   |   |   |--- priors_count <= 1.50\n",
      "|   |   |   |   |   |--- race_is_Hispanic <= 0.50\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- race_is_Hispanic >  0.50\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- priors_count >  1.50\n",
      "|   |   |   |   |   |--- sex <= 0.50\n",
      "|   |   |   |   |   |   |--- c_charge_degree <= 0.50\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- c_charge_degree >  0.50\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- sex >  0.50\n",
      "|   |   |   |   |   |   |--- age <= 24.50\n",
      "|   |   |   |   |   |   |   |--- race_is_African-American <= 0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- race_is_African-American >  0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- age >  24.50\n",
      "|   |   |   |   |   |   |   |--- juv_misd_count <= 0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- juv_misd_count >  0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |--- age >  32.50\n",
      "|   |   |   |   |--- class: 1\n",
      "|--- priors_count >  2.50\n",
      "|   |--- age <= 33.50\n",
      "|   |   |--- priors_count <= 7.50\n",
      "|   |   |   |--- age <= 27.50\n",
      "|   |   |   |   |--- c_charge_degree <= 0.50\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- c_charge_degree >  0.50\n",
      "|   |   |   |   |   |--- age <= 25.50\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- age >  25.50\n",
      "|   |   |   |   |   |   |--- priors_count <= 3.50\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- priors_count >  3.50\n",
      "|   |   |   |   |   |   |   |--- priors_count <= 4.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- priors_count >  4.50\n",
      "|   |   |   |   |   |   |   |   |--- age <= 26.50\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- age >  26.50\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |--- age >  27.50\n",
      "|   |   |   |   |--- sex <= 0.50\n",
      "|   |   |   |   |   |--- priors_count <= 5.50\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- priors_count >  5.50\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- sex >  0.50\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |--- priors_count >  7.50\n",
      "|   |   |   |--- age <= 27.50\n",
      "|   |   |   |   |--- priors_count <= 22.50\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- priors_count >  22.50\n",
      "|   |   |   |   |   |--- class: 0\n",
      "|   |   |   |--- age >  27.50\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |--- age >  33.50\n",
      "|   |   |--- priors_count <= 6.50\n",
      "|   |   |   |--- age <= 55.50\n",
      "|   |   |   |   |--- priors_count <= 4.50\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- priors_count >  4.50\n",
      "|   |   |   |   |   |--- race_is_Hispanic <= 0.50\n",
      "|   |   |   |   |   |   |--- age <= 36.50\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- age >  36.50\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- race_is_Hispanic >  0.50\n",
      "|   |   |   |   |   |   |--- age <= 41.00\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- age >  41.00\n",
      "|   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |--- age >  55.50\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |   |--- priors_count >  6.50\n",
      "|   |   |   |--- priors_count <= 15.50\n",
      "|   |   |   |   |--- juv_other_count <= 0.50\n",
      "|   |   |   |   |   |--- age <= 59.50\n",
      "|   |   |   |   |   |   |--- juv_misd_count <= 2.50\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- juv_misd_count >  2.50\n",
      "|   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- age >  59.50\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- juv_other_count >  0.50\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |   |--- priors_count >  15.50\n",
      "|   |   |   |   |--- age <= 50.50\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- age >  50.50\n",
      "|   |   |   |   |   |--- race_is_Hispanic <= 0.50\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- race_is_Hispanic >  0.50\n",
      "|   |   |   |   |   |   |--- class: 0\n",
      "\n",
      "LDA test accuracy: 0.66\n",
      "Logistic Regression test accuracy: 0.67\n",
      "Random Forest test accuracy: 0.67\n",
      "Gradient Boosting test accuracy: 0.66\n",
      "Bagging Classifier test accuracy: 0.63\n",
      "SVC test accuracy: 0.67\n"
     ]
    }
   ],
   "source": [
    "#Author: Henry Moore, with help from Divik Verma and Catherine Chu\n",
    "#Date: July 24, 2024\n",
    "#Assignment: Math 76.01 Homework 4, Decision trees, interpretability, and algorithmic bias\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#1.1\n",
    "# load data\n",
    "raw_data = pd.read_csv('/Users/henrymoore/Desktop/mathai2/compas-scores-two-years.csv')\n",
    "# print a list of variable names\n",
    "print(raw_data.columns)\n",
    "# look at the first 5 rows \n",
    "raw_data.head(5)\n",
    "\n",
    "#1.2\n",
    "# Select features and response variables\n",
    "\n",
    "# Features by type\n",
    "numerical_features = ['juv_misd_count', 'juv_other_count', 'juv_fel_count', \n",
    "    'priors_count', 'age']\n",
    "binary_categorical_features = ['sex', 'c_charge_degree']\n",
    "other_categorical_features = ['race']\n",
    "all_features = binary_categorical_features + other_categorical_features + numerical_features\n",
    "\n",
    "# Possible esponse variables\n",
    "response_variables = ['is_recid', 'is_violent_recid', 'two_year_recid']\n",
    "\n",
    "# Variables that are used for data cleaning\n",
    "check_variables = ['days_b_screening_arrest']\n",
    "\n",
    "# Subselect data\n",
    "df = raw_data[all_features+response_variables+check_variables]\n",
    "\n",
    "# Apply filters\n",
    "df = df[(df['days_b_screening_arrest'] <= 30) & \n",
    "        (df['days_b_screening_arrest'] >= -30) & \n",
    "        (df['is_recid'] != -1) & \n",
    "        (df['c_charge_degree'] != 'O')]\n",
    "\n",
    "df = df[all_features+response_variables]\n",
    "print('Dataframe has {} rows and {} columns.'.format(df.shape[0], df.shape[1]))\n",
    "\n",
    "#Variables like charge degree and prior offenses count seem like they might be could predictors. \n",
    "#Variables relating to the recidivism offense, like recidivism score, seem like sensible outcome variables.\n",
    "\n",
    "#1.3\n",
    "# Code binary features as 0 and 1\n",
    "for x in binary_categorical_features:\n",
    "    for new_value, value in enumerate(set(df[x])):\n",
    "        print(\"Replace {} with {}.\".format(value, new_value))\n",
    "        df = df.replace(value, new_value)\n",
    "\n",
    "# Use 1-hot encoding for other categorical variables\n",
    "one_hot_features = []\n",
    "for x in other_categorical_features:\n",
    "    for new_feature, value in enumerate(set(df[x])):\n",
    "        feature_name = \"{}_is_{}\".format(x,value)\n",
    "        df.insert(3, feature_name, df[x]==value)\n",
    "        one_hot_features += [feature_name]\n",
    "\n",
    "# Check what the data frame looks like now\n",
    "df.head(10)\n",
    "\n",
    "#1.4\n",
    "# list of features\n",
    "features = numerical_features + binary_categorical_features + one_hot_features\n",
    "\n",
    "# features data frame\n",
    "X = df[features]\n",
    "\n",
    "# responses data frame\n",
    "Y = df[response_variables]\n",
    "\n",
    "# Split the data into a training set containing 90% of the data\n",
    "# and test set containing 10% of the data\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=42)\n",
    "\n",
    "#2.1\n",
    "# Create a model\n",
    "tree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Fit model to training data\n",
    "tree.fit(X_train, Y_train)\n",
    "\n",
    "# Evaluate training accuracy\n",
    "train_predictions = tree.predict(X_train)\n",
    "accuracy = accuracy_score(Y_train, train_predictions)\n",
    "\n",
    "# Check size of decision tree\n",
    "num_leaves = tree.get_n_leaves()\n",
    "\n",
    "# Report results\n",
    "print('Trained decision tree with {} leaves and training accuracy {:.2f}.'.format(num_leaves, accuracy))\n",
    "\n",
    "#2.2\n",
    "# Perform 5-fold cross-validation for different tree sizes\n",
    "\n",
    "print('Leaves\\tMean accuracy')\n",
    "print('---------------------')\n",
    "# With 100-1800 test, highest scores were 100 and 200, so size is adjusted accordingly\n",
    "for num_leaves in range(2,250,2):\n",
    "\n",
    "    # Trees must have at least 2 leaves\n",
    "    if num_leaves >= 2:\n",
    "\n",
    "        # construct a classifier with a limit on its number of leaves\n",
    "        temptree = DecisionTreeClassifier(max_leaf_nodes=num_leaves, random_state=42)\n",
    "        \n",
    "        # Get validation accuracy via 5-fold cross-validation\n",
    "        scores = cross_val_score(temptree, X_train, Y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "    print(\"{}\\t{:.5f}\".format(num_leaves,scores.mean()))\n",
    "\n",
    "#2.3 \n",
    "# In the previous test, we saw that 48 leaves yielded optimal accuracy\n",
    "# Create a model with the best number of leaves\n",
    "besttree = DecisionTreeClassifier(max_leaf_nodes=48, random_state=42)\n",
    "\n",
    "# Fit model to training data\n",
    "besttree.fit(X_train, Y_train)\n",
    "\n",
    "# Evaluate training accuracy\n",
    "train_predictions = besttree.predict(X_train)\n",
    "train_accuracy = accuracy_score(Y_train, train_predictions)\n",
    "\n",
    "# Evaluate test accuracy\n",
    "test_predictions = besttree.predict(X_test)\n",
    "test_accuracy = accuracy_score(Y_test, test_predictions)\n",
    "\n",
    "# Check size of decision tree\n",
    "num_leaves = besttree.get_n_leaves()\n",
    "\n",
    "# Report results\n",
    "print('Trained decision tree with {} leaves has training accuracy {:.2f}.'.format(num_leaves, train_accuracy))\n",
    "print('Trained decision tree with {} leaves has test accuracy {:.2f}.'.format(num_leaves, test_accuracy))\n",
    "\n",
    "#3.2\n",
    "# Create subset of training data without information on race. \n",
    "# (The information on race was encoded in the one-hot features.)\n",
    "remaining_features = [v for v in X.columns if v not in one_hot_features]\n",
    "X_train_sub = X_train[remaining_features]\n",
    "X_test_sub = X_test[remaining_features]\n",
    "\n",
    "# Create a model\n",
    "dtc = DecisionTreeClassifier(max_leaf_nodes=39)\n",
    "    \n",
    "# Fit model to training data\n",
    "dtc.fit(X_train_sub, Y_train['two_year_recid'])\n",
    "\n",
    "# Evaluate training accuracy\n",
    "y_pred = dtc.predict(X_test_sub)\n",
    "accuracy = (y_pred == Y_test['two_year_recid']).mean()\n",
    "\n",
    "# Check size of decision tree\n",
    "num_leaves = dtc.get_n_leaves()\n",
    "\n",
    "# Report results\n",
    "print('Trained decision tree with {} leaves and test accuracy {:.2f}.'.format(num_leaves, accuracy))\n",
    "\n",
    "#There is a 10-12% boost in accuracy by removing race as a feature in this classification problem. \n",
    "#This implies that race is a bad predictor and introduces unnecessary noise to our model that disappears when race is removed as a feature\n",
    "\n",
    "#3.3\n",
    "tree_without_race = export_text(dtc, feature_names=list(X_train_sub.columns))\n",
    "print(\"tree without race:\")\n",
    "print(tree_without_race)\n",
    "tree_with_race = export_text(besttree, feature_names=list(X_train.columns))\n",
    "print(\"tree with race:\")\n",
    "print(tree_with_race)\n",
    "\n",
    "#There are several locations in the first decision tree with race that include decisions that are made based on the race of the individual.\n",
    "#The fact that decisions are made based on the race of the invididual indicate racial bias.\n",
    "\n",
    "#4.3\n",
    "# Fit LDA\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train, Y_train['two_year_recid'])\n",
    "lda_pred = lda.predict(X_test)\n",
    "lda_accuracy = accuracy_score(Y_test['two_year_recid'], lda_pred)\n",
    "print(f'LDA test accuracy: {lda_accuracy:.2f}')\n",
    "\n",
    "# Fit Logistic Regression\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_train, Y_train['two_year_recid'])\n",
    "log_reg_pred = log_reg.predict(X_test)\n",
    "log_reg_accuracy = accuracy_score(Y_test['two_year_recid'], log_reg_pred)\n",
    "print(f'Logistic Regression test accuracy: {log_reg_accuracy:.2f}')\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier()\n",
    "param_dist_rf = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf_search = RandomizedSearchCV(rf, param_dist_rf, n_iter=10, cv=5, random_state=42)\n",
    "rf_search.fit(X_train, Y_train['two_year_recid'])\n",
    "rf_best = rf_search.best_estimator_\n",
    "rf_pred = rf_best.predict(X_test)\n",
    "rf_accuracy = accuracy_score(Y_test['two_year_recid'], rf_pred)\n",
    "print(f'Random Forest test accuracy: {rf_accuracy:.2f}')\n",
    "\n",
    "# Gradient Boosting\n",
    "gb = GradientBoostingClassifier()\n",
    "param_dist_gb = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "gb_search = RandomizedSearchCV(gb, param_dist_gb, n_iter=10, cv=5, random_state=42)\n",
    "gb_search.fit(X_train, Y_train['two_year_recid'])\n",
    "gb_best = gb_search.best_estimator_\n",
    "gb_pred = gb_best.predict(X_test)\n",
    "gb_accuracy = accuracy_score(Y_test['two_year_recid'], gb_pred)\n",
    "print(f'Gradient Boosting test accuracy: {gb_accuracy:.2f}')\n",
    "\n",
    "#Bagging Classifier\n",
    "bagging = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=100, random_state=42)\n",
    "bagging.fit(X_train, Y_train['two_year_recid'])\n",
    "bagging_pred = bagging.predict(X_test)\n",
    "bagging_accuracy = accuracy_score(Y_test['two_year_recid'], bagging_pred)\n",
    "print(f'Bagging Classifier test accuracy: {bagging_accuracy:.2f}')\n",
    "\n",
    "# Tune and fit SVC\n",
    "svc = SVC()\n",
    "param_dist_svc = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': [0.1, 0.01],\n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "\n",
    "svc_search = RandomizedSearchCV(svc, param_dist_svc, n_iter=5, cv=3, random_state=42)\n",
    "svc_search.fit(X_train, Y_train['two_year_recid'])\n",
    "svc_best = svc_search.best_estimator_\n",
    "svc_pred = svc_best.predict(X_test)\n",
    "svc_accuracy = accuracy_score(Y_test['two_year_recid'], svc_pred)\n",
    "print(f'SVC test accuracy: {svc_accuracy:.2f}')\n",
    "\n",
    "#All the models have comprable accuracy (within 2%) to the race-free tree, but only the bagging does worse.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mathai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
